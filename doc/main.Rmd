---
title: "ads_prj_3"
author: "Song WANG"
date: "2017Äê3ÔÂ14ÈÕ"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(gbm)
library(xgboost)
library(caret)
library(e1071)
library(plyr)
```



```{r}
img_label <- read.csv("labels.csv")
img_sift_feature_raw <- read.csv("sift_features.csv")
img_sift_feature <- data.frame(t(img_sift_feature_raw))
img_sift_feature <- cbind(img_sift_feature,img_label)

```
create training and test sets
```{r}
set.seed(1)
test_ind <- sample(1:5,2000,replace = T)
img_test <- img_sift_feature[which(test_ind==5),]
img_train <-img_sift_feature[which(test_ind!=5),]
fit_gbm<-gbm.fit(x=img_train[,1:5000],y=img_train[,5001],n.trees = 1200,distribution = "bernoulli",interaction.depth = 3,bag.fraction = 0.5,verbose = FALSE)
#img_train$V1 <- factor(img_train$V1)
#gbm1 <- gbm(formula = V1~., data = img_train, n.trees = 500)
#exp(predict(fit_gbm, img_train[,-5001], n.tree = 1000))

best_iter<-gbm.perf(fit_gbm,method = "OOB",plot.it = FALSE)
best_iter


#predict
gbm_predict<-predict(fit_gbm,newdata=img_test[,-5001],n.tree=fit_gbm$n.tree,type="response")
pre<-ifelse(gbm_predict>=0.5,1,0)
hist(pre)
mean(pre!=img_test[,5001])


#tune

#tc<-tune.control(cross = 5)

#tune_gbm<-tune(gbm.fit,V1~.,data = img_test,ranges = list(n.tree=c(500,100,1500),interaction.depth = c(2,3,4)),tunecontrol = tc, scale=FALSE)
```

#tuning parameters
```{r}
set.seed(2)
bootcontrol<-trainControl(number = 1)
gbm_grid<-expand.grid(.n.trees=(1:2)*500,.interaction.depth=3,.shrinkage=.1,.n.minobsinnode=10)
gbm_fit2<-train(img_train[,1:5000],factor(img_train[,5001]),method = "gbm",trControl = bootcontrol,verbose=FALSE,bag.fraction=0.5,tuneGrid = gbm_grid)
```

#sift_5000+svm
```{r}

tc<-tune.control(cross=5)
tuneSVM<-tune(svm,V1~.,data = img_train,kernel="linear",ranges = list(cost=c(5,10)),tunecontrol = tc,scale=FALSE)
best_svm<-tuneSVM$best.model
svm_predict<-ifelse(predict(best_svm,img_test[,-5001])>0.5,1,0)
error_svm<-mean(svm_predict!=img_test[,5001])




```

#sift_5000+logistic
```{r}
best_logistic<-glm(V1~.,family = binomial(link = "logit"),data = img_train)
log_predict<-ifelse(predict(best_logistic,img_test[,-5001])>0.5,1,0)
error_log<-mean(log_predict!=img_test[,5001])
```

#sift_5000+svm_kernel
```{r}
tuneSVMkernel<-tune(svm,V1~.,data = img_train,kernel="radial",ranges = list(cost=10,gamma=5),tunecontrol = tc,scale=FALSE)
best_kernel<-tuneSVMkernel$best.model
kernel_predict<-ifelse(predict(best_kernel,img_test[,-5001])>0.5,1,0)
error_kernel<-mean(kernel_predict!=img_test[,5001])
```

#sift_5000+knn
```{r}
full.data<-img_train[,-5001]
full.dir<-img_train[,5001]
tuneKNN<-tune.knn(x=full.data,y=factor(full.dir),k=c(1,10,20),tunecontrol=tune.control(sampling = "cross"),cross=5)
tuneKNN2<-tune.knn(x=full.data,y=factor(full.dir),k=c(3,5),tunecontrol=tune.control(sampling = "cross"),cross=5)
tuneKNN3<-tune.knn(x=full.data,y=factor(full.dir),k=2,tunecontrol=tune.control(sampling = "cross"),cross=5)
summary(tuneKNN3)
summary(tuneKNN2)
summary(tuneKNN)
```

```{r}

```

