---
title: "Project 3 - Example Main Script"
author: "Yuting Ma, Tian Zheng"
date: "February 24, 2016"
output:
  pdf_document: default
  html_document: default
---
In your final repo, there should be an R markdown file that organizes **all computational steps** for evaluating your proposed image classification framework. 

This file is currently a template for running evaluation experiments of image analysis (or any predictive modeling). You should update it according to your codes but following precisely the same structure. 

```{r}

install.packages("caret")
install.packages("gbm")
install.packages("xgboost")
install.packages("e1071")

library(gbm)
library(caret)
library(xgboost)
library(e1071)

```

### Step 0: Import visual features and prepare training and testing data

First, set the working directory to the folder where features are stored. HoG features are generated from MATLAB and we keep the first 200 principal components to avoid overfitting. Specify the training and the testing set to create your own testing data by random subsampling. In order to obain reproducible results, set.seed() whenever randomization is used. If you are interested in reading raw images, please follow the path ../spr2017-proj3-group5/data/raw_images.

```{r wkdir, eval=FALSE}
setwd("/Users/apple/Documents/R/spr2017-proj3-group5/data") 
img_sift_feature_raw <- read.csv("sift_features.csv")
img_sift_feature <- data.frame(t(img_sift_feature_raw))
img_hog_feature_raw <- read.csv("HoG_features.csv",header = FALSE)
img_hog_feature_raw <- img_hog_feature_raw[,1:200]
img_hog_feature <- data.frame(img_hog_feature_raw)
#set test and training data
set.seed(1)
test_ind <- sample(1:5,2000,replace = T)
hog_test <- img_hog_feature[which(test_ind==5),]
hog_train <-img_hog_feature[which(test_ind!=5),]
sift_test <- img_sift_feature[which(test_ind==5),]
sift_train <-img_sift_feature[which(test_ind!=5),]


```


### Step 1: set up controls for evaluation experiments.

In this chunk, ,we have a set of controls for the evaluation experiments. 

+ (T/F) cross-validation on the training set
+ (number) K, the number of CV folds
+ (T/F) process features for training set
+ (T/F) run evaluation on an independent train set
+ (T/F) run evaluation on an independent test set

```{r exp_setup}
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.train=TRUE #run evaluation on an independent train set
run.test=TRUE # run evaluation on an independent test set
```

Using cross-validation or independent test set evaluation, we compare the performance of different classifiers or classifiers with different specifications. In this example, we use GBM with different `depth`. In the following chunk, we list, in a vector, setups (in this case, `depth`) corresponding to models that we will compare. In your project, you maybe comparing very different classifiers. You can assign them numerical IDs and labels specific to your project. 

```{r baseline_model_setup}
#for baseline gbm
depth <- 1   #set interaction.depth
n_trees <- seq(1000, 2000, 100)
shrinkage <- 0.001
model_label_gbm = paste("GBM with n_trees =", n_trees)

#for advanced svm_radial
cost <- seq(5,20,5)
gamma <- seq(0.001,0.009,0.002)
model_labels_svm = paste("svm with cost=",cost," gamma=",gamma)
```

### Step 2: import images class labels.

In this step, you can import class labels for train and test subset and factorize them for classification use.

```{r train_label,warning=FALSE}
setwd("/Users/apple/Documents/R/spr2017-proj3-group5/data") 
img_label <- read.csv("labels.csv")
label_test<-img_label[which(test_ind==5),]
label_train<-img_label[which(test_ind!=5),]
label_train <- factor(label_train)
label_test <- factor(label_test)
hog_train_new<-cbind(hog_train,label_train)
```



### Step 3: Train a classification model with training images
Call the train model and test model from library. 

`train.R` and `test.R` should be wrappers for all your model training steps and your classification/prediction steps. 
+ `train.R`
  + Input: a path that points to the training set features.
  + Input: an R object of training sample labels.
  + Output: an RData file that contains trained classifiers in the forms of R objects: models/settings/links to external trained configurations.
+ `test.R`
  + Input: a path that points to the test set features.
  + Input: an R object that contains a trained classifiers.
  + Output: an R object of class label predictions on the test set. If there are multiple classifiers under evaluation, there should be multiple sets of label predictions. 
```{r loadlib}
source("../lib/train.R")
source("../lib/test.R")
```

#### Model selection with cross-validation and Choose the "best" parameter value
* Do model selection by choosing among different values of training model parameters, that is, the interaction depth for GBM and cost & gamma for advanced model(SVM). 
```{r runcv, message=FALSE, warning=FALSE}
source("../lib/cross_validation.R")
if(run.cv){
  cv.function(K,n_trees, cost, gamma)
  }
  
```

* Train the model with the entire training set using the selected model (model parameter) via cross-validation.
```{r final_train}
if(run.train){
  train_result <- fit_train(best_ntree, best_gamma, best_cost)
  save(train_result, file="../output/fit_train.RData")
}
```

### Step 5: Make prediction 
Feed the final training model with the completely holdout testing data. 
```{r test}

tm_test=NA
if(run.test){
  test_result <- fit_test()
  # load(file=paste0("../output/feature_", "zip", "_", "test", ".RData"))
  # load(file="../output/fit_train.RData")
  save(test_result, file="../output/pred_test.RData")
}
```

### Summarize Running Time
Prediction performance matters, do does the running times for constructing features and for training the model, especially when the computation resource is limited. 
```{r running_time}

cat("Time for training baseline gbm model=", gbm_train_time, "s \n")
cat("Time for training advanced svm model=", svm_train_time, "s \n")
cat("Time for making prediction using baseline gbm model", test_tmg, "s \n")
cat("Time for making prediction using advanced svm model", test_tms, "s \n")
```
